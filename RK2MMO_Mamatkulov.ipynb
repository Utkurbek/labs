{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "RK2MMO_Mamatkulov.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbbaSbL4lews"
      },
      "source": [
        "Рубежный контроль №2\n",
        "Студент группы ИУ5-21М\n",
        "Маматкулов Уткурбек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_MU4oFglew7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, Tuple\n",
        "from scipy import stats\n",
        "from IPython.display import Image\n",
        "from sklearn.datasets import load_iris, load_boston\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline \n",
        "sns.set(style=\"ticks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRIU_vfOlew-"
      },
      "source": [
        "def accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray) -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Вычисление метрики accuracy для каждого класса\n",
        "    y_true - истинные значения классов\n",
        "    y_pred - предсказанные значения классов\n",
        "    Возвращает словарь: ключ - метка класса, \n",
        "    значение - Accuracy для данного класса\n",
        "    \"\"\"\n",
        "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
        "    d = {'t': y_true, 'p': y_pred}\n",
        "    df = pd.DataFrame(data=d)\n",
        "    # Метки классов\n",
        "    classes = np.unique(y_true)\n",
        "    # Результирующий словарь\n",
        "    res = dict()\n",
        "    # Перебор меток классов\n",
        "    for c in classes:\n",
        "        # отфильтруем данные, которые соответствуют \n",
        "        # текущей метке класса в истинных значениях\n",
        "        temp_data_flt = df[df['t']==c]\n",
        "        # расчет accuracy для заданной метки класса\n",
        "        temp_acc = accuracy_score(\n",
        "            temp_data_flt['t'].values, \n",
        "            temp_data_flt['p'].values)\n",
        "        # сохранение результата в словарь\n",
        "        res[c] = temp_acc\n",
        "    return res\n",
        "\n",
        "def print_accuracy_score_for_classes(\n",
        "    y_true: np.ndarray, \n",
        "    y_pred: np.ndarray):\n",
        "    \"\"\"\n",
        "    Вывод метрики accuracy для каждого класса\n",
        "    \"\"\"\n",
        "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
        "    if len(accs)>0:\n",
        "        print('Метка \\t Accuracy')\n",
        "    for i in accs:\n",
        "        print('{} \\t {}'.format(i, accs[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTKB5Xi7lexE"
      },
      "source": [
        "data = pd.read_csv('spam_classif.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsyagxTElexI",
        "outputId": "75b669c6-e589-4adf-e26b-748286d916cc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs2aAoYNlexQ",
        "outputId": "b839ca94-fa07-4087-f863-292a87b957a5"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aADx3t93lexS",
        "outputId": "d43f3038-19c9-4e4f-85cd-0bdcc9ada392"
      },
      "source": [
        "#le = LabelEncoder()\n",
        "category_columns = ['Category']\n",
        "for col in category_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Category                                            Message\n",
              "0            0  Go until jurong point, crazy.. Available only ...\n",
              "1            0                      Ok lar... Joking wif u oni...\n",
              "2            1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3            0  U dun say so early hor... U c already then say...\n",
              "4            0  Nah I don't think he goes to usf, he lives aro...\n",
              "...        ...                                                ...\n",
              "5567         1  This is the 2nd time we have tried 2 contact u...\n",
              "5568         0               Will ü b going to esplanade fr home?\n",
              "5569         0  Pity, * was in mood for that. So...any other s...\n",
              "5570         0  The guy did some bitching but I acted like i'd...\n",
              "5571         0                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuZemfP6lexT",
        "outputId": "e1dbad17-9909-4e50-eea5-416fb7bedbee"
      },
      "source": [
        "# Сформируем общий словарь для обучения моделей из обучающей и тестовой выборки\n",
        "vocab_list = data['Message'].tolist()\n",
        "vocab_list[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ok lar... Joking wif u oni...',\n",
              " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
              " 'U dun say so early hor... U c already then say...',\n",
              " \"Nah I don't think he goes to usf, he lives around here though\",\n",
              " \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\",\n",
              " 'Even my brother is not like to speak with me. They treat me like aids patent.',\n",
              " \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\",\n",
              " 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
              " 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uhJqRdRlexU",
        "outputId": "6763ce74-0593-4a95-f8c9-c318b96b027e"
      },
      "source": [
        "vocabVect = CountVectorizer()\n",
        "vocabVect.fit(vocab_list)\n",
        "corpusVocab = vocabVect.vocabulary_\n",
        "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Количество сформированных признаков - 8709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKqnt5VSlexV",
        "outputId": "d77089e7-ade0-4d3f-b440-8c2a2d514510"
      },
      "source": [
        "for i in list(corpusVocab)[1:10]:\n",
        "    print('{}={}'.format(i, corpusVocab[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "until=8080\n",
            "jurong=4370\n",
            "point=5954\n",
            "crazy=2334\n",
            "available=1313\n",
            "only=5567\n",
            "in=4110\n",
            "bugis=1763\n",
            "great=3651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CemXF6fKlexW"
      },
      "source": [
        "# Векторизация текста на основе модели \"мешка слов\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY2kL7aTlexX"
      },
      "source": [
        "### Использование класса CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnHvXKf-lexY"
      },
      "source": [
        "#### Подсчитывает количество слов словаря, входящих в данный текст."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYq0vTCFlexZ",
        "outputId": "419e0d41-ad20-4a2f-d297-6eb71aa43597"
      },
      "source": [
        "test_features = vocabVect.transform(vocab_list)\n",
        "test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5572x8709 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 74098 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yLelsPolexZ",
        "outputId": "23b6bf1d-ef2f-4c38-d571-a58cb9567c7b"
      },
      "source": [
        "test_features.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISOm2HPWlexa",
        "outputId": "6a8941d7-8ce7-44e6-8a6b-a7da26d7f07b"
      },
      "source": [
        "# Размер нулевой строки\n",
        "len(test_features.todense()[0].getA1())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8709"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhhja0Qglexb",
        "outputId": "91d33d2d-195a-4477-b070-0b0f60a7a70f"
      },
      "source": [
        "# Непустые значения нулевой строки\n",
        "[i for i in test_features.todense()[0].getA1() if i>0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnTUJKT3lexc",
        "outputId": "15f6c8b8-fca5-40b3-9a21-c343bc63e6fb"
      },
      "source": [
        "vocabVect.get_feature_names()[1000:1020]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aid',\n",
              " 'aids',\n",
              " 'aig',\n",
              " 'aight',\n",
              " 'ain',\n",
              " 'aint',\n",
              " 'air',\n",
              " 'air1',\n",
              " 'airport',\n",
              " 'airtel',\n",
              " 'aiya',\n",
              " 'aiyah',\n",
              " 'aiyar',\n",
              " 'aiyo',\n",
              " 'ajith',\n",
              " 'ak',\n",
              " 'aka',\n",
              " 'akon',\n",
              " 'al',\n",
              " 'alaikkum']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKAOdQGMlexc"
      },
      "source": [
        "N-грамм"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_5Wqkhg3lexd",
        "outputId": "1c2d4517-ee24-4bba-f950-0f70dfca4985"
      },
      "source": [
        "ncv = CountVectorizer(ngram_range=(1,3))\n",
        "ngram_features = ncv.fit_transform(vocab_list)\n",
        "ngram_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5572x104934 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 217339 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VKnuTJKlexe",
        "outputId": "74f42a53-5094-446c-d8f6-bfd58869a080"
      },
      "source": [
        "len(ncv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U10B7H5Glexg",
        "outputId": "c6b3576c-a4b3-4e20-9105-c5d54e24f40b"
      },
      "source": [
        "# Теперь признаками являются N-граммы\n",
        "ncv.get_feature_names()[10000:10020]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['at mine just',\n",
              " 'at moment',\n",
              " 'at moment evone',\n",
              " 'at moment yeah',\n",
              " 'at mp3',\n",
              " 'at mp3 player',\n",
              " 'at mrt',\n",
              " 'at mrt station',\n",
              " 'at mu',\n",
              " 'at mu and',\n",
              " 'at mu in',\n",
              " 'at mu you',\n",
              " 'at my',\n",
              " 'at my great',\n",
              " 'at my house',\n",
              " 'at my moms',\n",
              " 'at my mum',\n",
              " 'at my parents',\n",
              " 'at my phone',\n",
              " 'at my place']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljaiNr_Xlexi"
      },
      "source": [
        "### Использование класса TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFBEu2Rylexi",
        "outputId": "6050a1cf-fe51-4550-c783-c8ceea76d82e"
      },
      "source": [
        "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
        "tfidf_ngram_features = tfidfv.fit_transform(vocab_list)\n",
        "tfidf_ngram_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5572x104934 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 217339 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKLa5DD9lexj",
        "outputId": "fcf081fd-20bd-43a5-b8b1-7f7e7aeea900"
      },
      "source": [
        "tfidf_ngram_features.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHPrckSvlexk",
        "outputId": "82b662cb-7484-43ec-81ec-2eb4589193f5"
      },
      "source": [
        "# Размер нулевой строки\n",
        "len(tfidf_ngram_features.todense()[0].getA1())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLLjJnMzlexl",
        "outputId": "3eb9cfc3-ce10-495c-d801-4a342e9ba352"
      },
      "source": [
        "# Непустые значения нулевой строки\n",
        "[i for i in tfidf_ngram_features.todense()[0].getA1() if i>0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.11501101620597226,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.14678507188449502,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.12990107976500484,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.12990107976500484,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.11908021199485914,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.06964712666694571,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.07208549828613442,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.08493973105393231,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.050435116339348454,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.12990107976500484,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.07365148623113625,\n",
              " 0.14678507188449502,\n",
              " 0.1537647471633528,\n",
              " 0.12026785509880393,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.07324643231209632,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.10833602139962993,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528,\n",
              " 0.08591436854273743,\n",
              " 0.10400989550811528,\n",
              " 0.1537647471633528,\n",
              " 0.1537647471633528]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOOEN393lexm"
      },
      "source": [
        "## Решение задачи классификации спама на основе модели \"мешка слов\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANSn_zi-lexm"
      },
      "source": [
        "С использованием кросс-валидации попробуем применить к корпусу текстов различные варианты векторизации и классификации."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLtnsPkIlexn"
      },
      "source": [
        "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
        "    for v in vectorizers_list:\n",
        "        for c in classifiers_list:\n",
        "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
        "            score = cross_val_score(pipeline1, data['Message'], data['Category'], scoring='accuracy', cv=3).mean()\n",
        "            print('Векторизация - {}'.format(v))\n",
        "            print('Модель для классификации - {}'.format(c))\n",
        "            print('Accuracy = {}'.format(score))\n",
        "            print('===========================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilog5taplexn",
        "outputId": "457cf56b-7a3c-4c46-84af-e4e017d38c56"
      },
      "source": [
        "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
        "classifiers_list = [RandomForestClassifier(), ComplementNB()]\n",
        "VectorizeAndClassify(vectorizers_list, classifiers_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '000pes': 2, '008704050406': 3,\n",
            "                            '0089': 4, '0121': 5, '01223585236': 6,\n",
            "                            '01223585334': 7, '0125698789': 8, '02': 9,\n",
            "                            '0207': 10, '02072069400': 11, '02073162414': 12,\n",
            "                            '02085076972': 13, '021': 14, '03': 15, '04': 16,\n",
            "                            '0430': 17, '05': 18, '050703': 19, '0578': 20,\n",
            "                            '06': 21, '07': 22, '07008009200': 23,\n",
            "                            '07046744435': 24, '07090201529': 25,\n",
            "                            '07090298926': 26, '07099833605': 27,\n",
            "                            '07123456789': 28, '0721072': 29, ...})\n",
            "Модель для классификации - RandomForestClassifier()\n",
            "Accuracy = 0.9725405031708299\n",
            "===========================\n",
            "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '000pes': 2, '008704050406': 3,\n",
            "                            '0089': 4, '0121': 5, '01223585236': 6,\n",
            "                            '01223585334': 7, '0125698789': 8, '02': 9,\n",
            "                            '0207': 10, '02072069400': 11, '02073162414': 12,\n",
            "                            '02085076972': 13, '021': 14, '03': 15, '04': 16,\n",
            "                            '0430': 17, '05': 18, '050703': 19, '0578': 20,\n",
            "                            '06': 21, '07': 22, '07008009200': 23,\n",
            "                            '07046744435': 24, '07090201529': 25,\n",
            "                            '07090298926': 26, '07099833605': 27,\n",
            "                            '07123456789': 28, '0721072': 29, ...})\n",
            "Модель для классификации - ComplementNB()\n",
            "Accuracy = 0.9664390153607633\n",
            "===========================\n",
            "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '000pes': 2, '008704050406': 3,\n",
            "                            '0089': 4, '0121': 5, '01223585236': 6,\n",
            "                            '01223585334': 7, '0125698789': 8, '02': 9,\n",
            "                            '0207': 10, '02072069400': 11, '02073162414': 12,\n",
            "                            '02085076972': 13, '021': 14, '03': 15, '04': 16,\n",
            "                            '0430': 17, '05': 18, '050703': 19, '0578': 20,\n",
            "                            '06': 21, '07': 22, '07008009200': 23,\n",
            "                            '07046744435': 24, '07090201529': 25,\n",
            "                            '07090298926': 26, '07099833605': 27,\n",
            "                            '07123456789': 28, '0721072': 29, ...})\n",
            "Модель для классификации - RandomForestClassifier()\n",
            "Accuracy = 0.975412422357128\n",
            "===========================\n",
            "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '000': 1, '000pes': 2, '008704050406': 3,\n",
            "                            '0089': 4, '0121': 5, '01223585236': 6,\n",
            "                            '01223585334': 7, '0125698789': 8, '02': 9,\n",
            "                            '0207': 10, '02072069400': 11, '02073162414': 12,\n",
            "                            '02085076972': 13, '021': 14, '03': 15, '04': 16,\n",
            "                            '0430': 17, '05': 18, '050703': 19, '0578': 20,\n",
            "                            '06': 21, '07': 22, '07008009200': 23,\n",
            "                            '07046744435': 24, '07090201529': 25,\n",
            "                            '07090298926': 26, '07099833605': 27,\n",
            "                            '07123456789': 28, '0721072': 29, ...})\n",
            "Модель для классификации - ComplementNB()\n",
            "Accuracy = 0.9675155382353525\n",
            "===========================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNbLPYF1lexo"
      },
      "source": [
        "## Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Tu2uLzlexp"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.5, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ywi08ylexp"
      },
      "source": [
        "def spam(v, c):\n",
        "    model = Pipeline(\n",
        "        [(\"vectorizer\", v), \n",
        "         (\"classifier\", c)])\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print_accuracy_score_for_classes(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0zqtOPNlexq",
        "outputId": "281ed12e-48f7-4ef2-da1c-a8e101809935"
      },
      "source": [
        "spam(TfidfVectorizer(), RandomForestClassifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 0.9983354140657511\n",
            "1 \t 0.7911227154046997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_721RDvlexr",
        "outputId": "082cb9b2-fe49-4e52-b975-1288a1cfeff4"
      },
      "source": [
        "spam(TfidfVectorizer(ngram_range=(1,3)), RandomForestClassifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 1.0\n",
            "1 \t 0.6657963446475196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzRHvLNelexs",
        "outputId": "c09a829b-4e91-4d39-d890-b33acdcc7fba"
      },
      "source": [
        "spam(TfidfVectorizer(ngram_range=(2,3)), RandomForestClassifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 1.0\n",
            "1 \t 0.6161879895561357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96wyw9Dzlext",
        "outputId": "0b60d9de-709c-42f3-d7e4-72c67e6768a8"
      },
      "source": [
        "spam(TfidfVectorizer(ngram_range=(1,4)), RandomForestClassifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 1.0\n",
            "1 \t 0.639686684073107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMjyEabGlexu",
        "outputId": "2f5f6058-34ac-4f47-b366-2536748639a5"
      },
      "source": [
        "spam(TfidfVectorizer(ngram_range=(2,4)), RandomForestClassifier())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка \t Accuracy\n",
            "0 \t 1.0\n",
            "1 \t 0.5509138381201044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovjv9sjSlexv"
      },
      "source": [
        "Таким образом, TFidf вариант векторизации признаков в паре с RandomForestClassifier классификатором показал лучшее качество. Точность составила 0.975412422357128."
      ]
    }
  ]
}